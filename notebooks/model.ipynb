{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHamaCwlo0QC"
      },
      "source": [
        "http://vision.stanford.edu/aditya86/ImageNetDogs/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksPE3o7SdcT2",
        "outputId": "ad67cc85-e1dc-4241-b67d-91e39022917d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib as plt\n",
        "\n",
        "# Define the transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the data\n",
        "train_data = torchvision.datasets.ImageFolder(root=\"output/train/\", transform=transform)\n",
        "test_data = torchvision.datasets.ImageFolder(root=\"output/test/\", transform=transform)\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T3KTJpNGEE7c"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xqlEybUkdiAL"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import inception_v3\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq5fLFzSdl9Y",
        "outputId": "4114e4be-7b2f-4b1d-a48e-1ec25e282b4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = inception_v3(pretrained=True)\n",
        "\n",
        "# Replace the last layer\n",
        "num_features = model.fc.in_features\n",
        "   \n",
        "class Multiclass_Net(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden1, n_hidden2, n_hidden3, n_output):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(n_input, n_hidden1)\n",
        "        self.hidden2 = nn.Linear(n_hidden1, n_hidden2)\n",
        "        self.hidden3 = nn.Linear(n_hidden2, n_hidden3)\n",
        "        self.out = nn.Linear(n_hidden3, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        x = F.relu(self.hidden3(x))\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate our neural network\n",
        "# n_input=4 since we have 4 features\n",
        "# n_output=3 since we have 3 classes\n",
        "net = Multiclass_Net(n_input=num_features, n_hidden1=224, n_hidden2=75, n_hidden3=10, n_output=len(train_data.classes))\n",
        "model.fc = nn.Linear(num_features, len(train_data.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "foSpMPOFd5Hm"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Move the model to the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZH8ML_nCm8cQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model,criterion,optimizer,trainloader,num_iter,device, len_train_data):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train() # Set the model to training mode\n",
        "\n",
        "    cost = []\n",
        "\n",
        "    for epoch in range(num_iter):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(trainloader):\n",
        "\n",
        "            # Get the inputs X and labels y for the minibatch\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # Zero the gradients of the weights each iteration\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate the predictions and the cost/loss\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Use autograd to calculate the gradient of the cost with respect to each weight\n",
        "            loss.backward()\n",
        "\n",
        "            # Use the optimizer to do the weights update\n",
        "            optimizer.step()\n",
        "\n",
        "            # Add the loss to running loss for the epoch\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Update the training loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        train_loss /= len_train_data\n",
        "        print(f\"Epoch [{epoch + 1}/{num_iter}] Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        cost.append(running_loss)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roafLeZbnEnB",
        "outputId": "281736df-1736-404d-c85b-a668e50f4e48"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (28704x299 and 2048x224)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m cost_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Plot the cost over training\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(cost_path)\n",
            "Cell \u001b[1;32mIn[20], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, trainloader, num_iter, device, len_train_data)\u001b[0m\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate the predictions and the cost/loss\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Use autograd to calculate the gradient of the cost with respect to each weight\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[18], line 16\u001b[0m, in \u001b[0;36mMulticlass_Net.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden2(x))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden3(x))\n",
            "File \u001b[1;32mc:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\keese\\anaconda3\\envs\\aipi\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28704x299 and 2048x224)"
          ]
        }
      ],
      "source": [
        "# Define the cost / loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define the method of updating the weights each iteration\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "# Number of iterations (epochs) to train\n",
        "n_iter = 10\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train model\n",
        "cost_path = train_model(net,criterion,optimizer,train_loader,n_iter,device,len(train_data))\n",
        "\n",
        "# Plot the cost over training\n",
        "plt.plot(cost_path)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSnDDMY1nH7z"
      },
      "outputs": [],
      "source": [
        "def test_model(model,testloader,device):\n",
        "    # Turn autograd off\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Set up lists to store true and predicted values\n",
        "        y_true = []\n",
        "        test_preds = []\n",
        "\n",
        "        # Calculate the predictions on the test set and add to list\n",
        "        for data in testloader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            # Feed inputs through model to get raw scores\n",
        "            logits = model.forward(inputs)\n",
        "            # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
        "            probs = F.softmax(logits,dim=1)\n",
        "            # Get discrete predictions using argmax\n",
        "            preds = np.argmax(probs.cpu().numpy(),axis=1)\n",
        "            test_preds.extend(preds)\n",
        "            y_true.extend(labels)\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        test_acc = np.sum(test_preds==y_test)/len(y_test)\n",
        "\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-tkN8PznKj9"
      },
      "outputs": [],
      "source": [
        "# Test model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "acc = test_model(model,test_loader,device)\n",
        "print('Test set accuracy is {:.3f}'.format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOdmV0-aeA3M"
      },
      "outputs": [],
      "source": [
        "# OPTION 2: Save the entire model\n",
        "\n",
        "model_dir = 'models/'\n",
        "os.makedirs(os.path.dirname(model_dir), exist_ok=True)\n",
        "filename = 'multi_class_model.pt'\n",
        "\n",
        "# Save the entire model\n",
        "torch.save(net, model_dir+filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1e9AQiCd_to",
        "outputId": "f9772b9e-7087-477e-9ad9-1b472d355107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] Train Loss: 2.3245 Test Loss: 0.8111 Test Acc: 0.8102\n",
            "Epoch [2/10] Train Loss: 0.7393 Test Loss: 0.5484 Test Acc: 0.8453\n",
            "Epoch [3/10] Train Loss: 0.4586 Test Loss: 0.4945 Test Acc: 0.8530\n",
            "Epoch [4/10] Train Loss: 0.3052 Test Loss: 0.4666 Test Acc: 0.8604\n",
            "Epoch [5/10] Train Loss: 0.2020 Test Loss: 0.4839 Test Acc: 0.8530\n",
            "Epoch [6/10] Train Loss: 0.1423 Test Loss: 0.4721 Test Acc: 0.8594\n",
            "Epoch [7/10] Train Loss: 0.1020 Test Loss: 0.4683 Test Acc: 0.8609\n",
            "Epoch [8/10] Train Loss: 0.0735 Test Loss: 0.4899 Test Acc: 0.8539\n",
            "Epoch [9/10] Train Loss: 0.0555 Test Loss: 0.4862 Test Acc: 0.8580\n",
            "Epoch [10/10] Train Loss: 0.0445 Test Loss: 0.5021 Test Acc: 0.8554\n"
          ]
        }
      ],
      "source": [
        "# Define the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Train the model on the training set\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Move the data to the device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the training loss\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            # Move the data to the device\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Update the test loss and accuracy\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            test_acc += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Print the training and test loss and accuracy\n",
        "    train_loss /= len(train_data)\n",
        "    test_loss /= len(test_data)\n",
        "    test_acc = test_acc.double() / len(test_data)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Train Loss: {train_loss:.4f} Test Loss: {test_loss:.4f} Test Acc: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
