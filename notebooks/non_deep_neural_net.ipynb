{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import urllib.request\n",
				"import tarfile\n",
				"import os\n",
				"import splitfolders\n",
				"import pandas as pd\n",
				"import cv2\n",
				"import os\n",
				"import numpy as np\n",
				"import pandas as pd\n",
				"from sklearn.linear_model import LogisticRegression\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Download the data\n",
				"if not os.path.exists('./data'):\n",
				"    os.mkdir('./data')\n",
				"if not os.path.exists('data/raw'):\n",
				"    url = 'http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar'\n",
				"    urllib.request.urlretrieve(url,filename='data/dogs.tar')\n",
				"    # Open the tar file\n",
				"    with tarfile.open('data/dogs.tar', 'r') as tar:\n",
				"        # Extract all files to the 'data/raw' directory\n",
				"        tar.extractall(path='data/raw')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"for subdir, dirs, files in os.walk(os.getcwd() + '/data/raw'):\n",
				"    for file in files:\n",
				"        filepath = subdir + os.sep + file\n",
				"\n",
				"        if filepath.endswith(\".jpg\"):\n",
				"            \n",
				"            folder = filepath.split(\"\\\\\")[-2].split(\"-\")[1]\n",
				"\n",
				"            if not os.path.isdir(os.getcwd() + \"/data/raw/images_folder/\" + folder): \n",
				"                os.makedirs(os.getcwd() + \"/data/raw/images_folder/\" + folder) \n",
				"            \n",
				"            os.rename(filepath, os.getcwd() + \"/data/raw/images_folder/\" + folder + \"/\" + filepath.split(\"\\\\\")[-1])\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"splitfolders.ratio('data/raw/images_folder', output='data/processed', seed=1337, ratio=(.8, 0.0,0.2)) "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def create_image_dict(img, breed):\n",
				"    i = 0 \n",
				"    image_dict= {}\n",
				"    for i_row in range(len(img)):\n",
				"        for i_col in img[i_row]:\n",
				"            image_dict[f'pixel_{i}'] = i_col\n",
				"            i+=1\n",
				"    image_dict['Breed'] = breed\n",
				"    \n",
				"    return image_dict"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def ordinal_encode(X,cols):\n",
				"    \"\"\"\n",
				"    Takes a dataframe as an input and applies ordinal encoding to the \n",
				"    specified columns\n",
				"\n",
				"    Inputs:\n",
				"        X(pd.DataFrame): dataframe\n",
				"        cols(list): list of columns to ordinal encode\n",
				"    \n",
				"    Return:\n",
				"        X(pd.DataFrame): dataframe\n",
				"        enc: ordinal encoder\n",
				"    \"\"\"\n",
				"    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
				"    # Fit the encoder on training data and transform it.  We can also use it to transform test data\n",
				"    X[cols] = enc.fit_transform(X[cols])\n",
				"    return X,enc"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"img_array = []\n",
				"for subdir, dirs, files in os.walk(os.getcwd() + '/data/processed/val/'):\n",
				"    for file in files:\n",
				"        filepath = subdir + os.sep + file\n",
				"\n",
				"        if filepath.endswith(\".jpg\"):\n",
				"            \n",
				"            breed = filepath.split(\"\\\\\")[-2].split('/')[-1]\n",
				"\n",
				"            # Read your images\n",
				"            img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
				"            img = cv2.resize(img, (225, 225))\n",
				"            img_array.append(create_image_dict(img, breed))\n",
				"\n",
				"# Create an empty DataFrame\n",
				"df = pd.DataFrame(img_array)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df, enc = ordinal_encode(df, ['Breed'])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Load your feature vectors (extracted from images) and labels\n",
				"X = df.drop(columns='Breed')\n",
				"y= df['Breed']\n",
				"\n",
				"# Split data into train and test sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
				"\n",
				"scaler = StandardScaler()\n",
				"X_train_scaled = scaler.fit_transform(X_train)\n",
				"X_test_scaled = scaler.transform(X_test)\n",
				"\n",
				"# Create and train the logistic regression model\n",
				"model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
				"model.fit(X_train, y_train)\n",
				"\n",
				"# Evaluate the model\n",
				"accuracy = model.score(X_test, y_test)\n",
				"print(f\"Accuracy: {accuracy:.2f}\")\n"
			]
		}
	],
	"metadata": {
		"colab": {
			"provenance": []
		},
		"kernelspec": {
			"display_name": "aipi540",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.6.15"
		},
		"vscode": {
			"interpreter": {
				"hash": "31cc86d7aac4849c7546154c9b56d60163d5e8a1d83593a5eed18774fbf4fd37"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 0
}
